{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aed3644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "from pathlib import Path\n",
    "from scipy.stats import probplot, chi2_contingency, chi2\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, roc_curve, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "import scipy.stats as stats\n",
    "import scikitplot as skplt\n",
    "import joblib\n",
    "import os\n",
    "from yellowbrick.model_selection import FeatureImportances\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05383e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\"postgresql://[user]:[password]@[location]:[port]/[database]\"\n",
    "from config import db_password\n",
    "db_string = f\"postgresql://postgres:{db_password}@127.0.0.1:5432/Proj\"\n",
    "engine = create_engine(db_string)\n",
    "credit_status = pd.read_sql(\"SELECT * FROM credit_record\", engine)\n",
    "cc_data_full_data = pd.read_sql(\"SELECT * FROM application_record\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e99ad0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diron\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\diron\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "C:\\Users\\diron\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\diron\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\diron\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "#1.2 creating the target variable\n",
    "begin_month=pd.DataFrame(credit_status.groupby(['id'])['months_balance'].agg(min))\n",
    "begin_month=begin_month.rename(columns={'months_balance':'Account age'})\n",
    "cc_data_full_data=pd.merge(cc_data_full_data,begin_month,how='left',on='id')\n",
    "credit_status['dep_value'] = None\n",
    "credit_status['dep_value'][credit_status['status'] =='2']='Yes'\n",
    "credit_status['dep_value'][credit_status['status'] =='3']='Yes'\n",
    "credit_status['dep_value'][credit_status['status'] =='4']='Yes'\n",
    "credit_status['dep_value'][credit_status['status'] =='5']='Yes'\n",
    "cpunt=credit_status.groupby('id').count()\n",
    "cpunt['dep_value'][cpunt['dep_value'] > 0]='Yes'\n",
    "cpunt['dep_value'][cpunt['dep_value'] == 0]='No'\n",
    "cpunt = cpunt[['dep_value']]\n",
    "cc_data_full_data = pd.merge(cc_data_full_data,cpunt,how='inner',on='id')\n",
    "cc_data_full_data['Is high risk']=cc_data_full_data['dep_value']\n",
    "cc_data_full_data.loc[cc_data_full_data['Is high risk']=='Yes','Is high risk']=1\n",
    "cc_data_full_data.loc[cc_data_full_data['Is high risk']=='No','Is high risk']=0\n",
    "cc_data_full_data.drop('dep_value',axis=1,inplace=True)\n",
    "warnings.simplefilter(action='always', category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd6c6602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the features to a more readable feature names\n",
    "cc_data_full_data = cc_data_full_data.rename(columns={\n",
    "    'code_gender':'Gender',\n",
    "    'flag_own_car':'Has a car',\n",
    "    'flag_own_realty':'Has a property',\n",
    "    'cnt_children':'Children count',\n",
    "    'amt_income_total':'Income',\n",
    "    'name_income_type':'Employment status',\n",
    "    'name_education_type':'Education level',\n",
    "    'name_family_status':'Marital status',\n",
    "    'name_housing_type':'Dwelling',\n",
    "    'days_birth':'Age',\n",
    "    'days_employed': 'Employment length',\n",
    "    'flag_mobil': 'Has a mobile phone',\n",
    "    'flag_work_phone': 'Has a work phone',\n",
    "    'flag_phone': 'Has a phone',\n",
    "    'flag_email': 'Has an email',\n",
    "    'occupation_type': 'Job title',\n",
    "    'cnt_fam_members': 'Family member count',\n",
    "    'Account age': 'Account age'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf08e7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into train and test\n",
    "def data_split(df, test_size):\n",
    "    train_df, test_df = train_test_split(df, test_size=test_size, random_state=42)\n",
    "    return train_df.reset_index(drop=True), test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7511a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_train_original, cc_test_original = data_split(cc_data_full_data, 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d6fec33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29165, 20)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_train_original.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4665ce7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7292, 20)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_test_original.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce2ca907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a copy of the dataset so that the original stays untouched\n",
    "cc_train_copy = cc_train_original.copy()\n",
    "cc_test_copy = cc_test_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "298e91f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Has a car</th>\n",
       "      <th>Has a property</th>\n",
       "      <th>Children count</th>\n",
       "      <th>Income</th>\n",
       "      <th>Employment status</th>\n",
       "      <th>Education level</th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Dwelling</th>\n",
       "      <th>Age</th>\n",
       "      <th>Employment length</th>\n",
       "      <th>Has a mobile phone</th>\n",
       "      <th>Has a work phone</th>\n",
       "      <th>Has a phone</th>\n",
       "      <th>Has an email</th>\n",
       "      <th>Job title</th>\n",
       "      <th>Family member count</th>\n",
       "      <th>Account age</th>\n",
       "      <th>Is high risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5008804</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>-12005</td>\n",
       "      <td>-4542</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5008805</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>-12005</td>\n",
       "      <td>-4542</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5008806</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-21474</td>\n",
       "      <td>-1134</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Security staff</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5008808</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-19110</td>\n",
       "      <td>-3051</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5008809</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-19110</td>\n",
       "      <td>-3051</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id Gender Has a car Has a property  Children count    Income  \\\n",
       "0  5008804      M         Y              Y               0  427500.0   \n",
       "1  5008805      M         Y              Y               0  427500.0   \n",
       "2  5008806      M         Y              Y               0  112500.0   \n",
       "3  5008808      F         N              Y               0  270000.0   \n",
       "4  5008809      F         N              Y               0  270000.0   \n",
       "\n",
       "      Employment status                Education level        Marital status  \\\n",
       "0               Working               Higher education        Civil marriage   \n",
       "1               Working               Higher education        Civil marriage   \n",
       "2               Working  Secondary / secondary special               Married   \n",
       "3  Commercial associate  Secondary / secondary special  Single / not married   \n",
       "4  Commercial associate  Secondary / secondary special  Single / not married   \n",
       "\n",
       "            Dwelling    Age  Employment length  Has a mobile phone  \\\n",
       "0   Rented apartment -12005              -4542                   1   \n",
       "1   Rented apartment -12005              -4542                   1   \n",
       "2  House / apartment -21474              -1134                   1   \n",
       "3  House / apartment -19110              -3051                   1   \n",
       "4  House / apartment -19110              -3051                   1   \n",
       "\n",
       "   Has a work phone  Has a phone  Has an email       Job title  \\\n",
       "0                 1            0             0            None   \n",
       "1                 1            0             0            None   \n",
       "2                 0            0             0  Security staff   \n",
       "3                 0            1             1     Sales staff   \n",
       "4                 0            1             1     Sales staff   \n",
       "\n",
       "   Family member count  Account age Is high risk  \n",
       "0                  2.0        -15.0            0  \n",
       "1                  2.0        -14.0            0  \n",
       "2                  2.0        -29.0            0  \n",
       "3                  1.0         -4.0            0  \n",
       "4                  1.0        -26.0            0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_data_full_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3befa5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 36457 entries, 0 to 36456\n",
      "Data columns (total 20 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   36457 non-null  int64  \n",
      " 1   Gender               36457 non-null  object \n",
      " 2   Has a car            36457 non-null  object \n",
      " 3   Has a property       36457 non-null  object \n",
      " 4   Children count       36457 non-null  int64  \n",
      " 5   Income               36457 non-null  float64\n",
      " 6   Employment status    36457 non-null  object \n",
      " 7   Education level      36457 non-null  object \n",
      " 8   Marital status       36457 non-null  object \n",
      " 9   Dwelling             36457 non-null  object \n",
      " 10  Age                  36457 non-null  int64  \n",
      " 11  Employment length    36457 non-null  int64  \n",
      " 12  Has a mobile phone   36457 non-null  int64  \n",
      " 13  Has a work phone     36457 non-null  int64  \n",
      " 14  Has a phone          36457 non-null  int64  \n",
      " 15  Has an email         36457 non-null  int64  \n",
      " 16  Job title            25134 non-null  object \n",
      " 17  Family member count  36457 non-null  float64\n",
      " 18  Account age          36457 non-null  float64\n",
      " 19  Is high risk         36457 non-null  object \n",
      "dtypes: float64(3), int64(8), object(9)\n",
      "memory usage: 5.8+ MB\n"
     ]
    }
   ],
   "source": [
    "cc_data_full_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e386fd37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Children count</th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "      <th>Employment length</th>\n",
       "      <th>Has a mobile phone</th>\n",
       "      <th>Has a work phone</th>\n",
       "      <th>Has a phone</th>\n",
       "      <th>Has an email</th>\n",
       "      <th>Family member count</th>\n",
       "      <th>Account age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.645700e+04</td>\n",
       "      <td>36457.000000</td>\n",
       "      <td>3.645700e+04</td>\n",
       "      <td>36457.000000</td>\n",
       "      <td>36457.000000</td>\n",
       "      <td>36457.0</td>\n",
       "      <td>36457.000000</td>\n",
       "      <td>36457.000000</td>\n",
       "      <td>36457.000000</td>\n",
       "      <td>36457.000000</td>\n",
       "      <td>36457.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.078227e+06</td>\n",
       "      <td>0.430315</td>\n",
       "      <td>1.866857e+05</td>\n",
       "      <td>-15975.173382</td>\n",
       "      <td>59262.935568</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.225526</td>\n",
       "      <td>0.294813</td>\n",
       "      <td>0.089722</td>\n",
       "      <td>2.198453</td>\n",
       "      <td>-26.164193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.187524e+04</td>\n",
       "      <td>0.742367</td>\n",
       "      <td>1.017892e+05</td>\n",
       "      <td>4200.549944</td>\n",
       "      <td>137651.334859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.417934</td>\n",
       "      <td>0.455965</td>\n",
       "      <td>0.285787</td>\n",
       "      <td>0.911686</td>\n",
       "      <td>16.501854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.008804e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.700000e+04</td>\n",
       "      <td>-25152.000000</td>\n",
       "      <td>-15713.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.042028e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.215000e+05</td>\n",
       "      <td>-19438.000000</td>\n",
       "      <td>-3153.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.074614e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.575000e+05</td>\n",
       "      <td>-15563.000000</td>\n",
       "      <td>-1552.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.115396e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.250000e+05</td>\n",
       "      <td>-12462.000000</td>\n",
       "      <td>-408.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.150487e+06</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.575000e+06</td>\n",
       "      <td>-7489.000000</td>\n",
       "      <td>365243.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  Children count        Income           Age  \\\n",
       "count  3.645700e+04    36457.000000  3.645700e+04  36457.000000   \n",
       "mean   5.078227e+06        0.430315  1.866857e+05 -15975.173382   \n",
       "std    4.187524e+04        0.742367  1.017892e+05   4200.549944   \n",
       "min    5.008804e+06        0.000000  2.700000e+04 -25152.000000   \n",
       "25%    5.042028e+06        0.000000  1.215000e+05 -19438.000000   \n",
       "50%    5.074614e+06        0.000000  1.575000e+05 -15563.000000   \n",
       "75%    5.115396e+06        1.000000  2.250000e+05 -12462.000000   \n",
       "max    5.150487e+06       19.000000  1.575000e+06  -7489.000000   \n",
       "\n",
       "       Employment length  Has a mobile phone  Has a work phone   Has a phone  \\\n",
       "count       36457.000000             36457.0      36457.000000  36457.000000   \n",
       "mean        59262.935568                 1.0          0.225526      0.294813   \n",
       "std        137651.334859                 0.0          0.417934      0.455965   \n",
       "min        -15713.000000                 1.0          0.000000      0.000000   \n",
       "25%         -3153.000000                 1.0          0.000000      0.000000   \n",
       "50%         -1552.000000                 1.0          0.000000      0.000000   \n",
       "75%          -408.000000                 1.0          0.000000      1.000000   \n",
       "max        365243.000000                 1.0          1.000000      1.000000   \n",
       "\n",
       "       Has an email  Family member count   Account age  \n",
       "count  36457.000000         36457.000000  36457.000000  \n",
       "mean       0.089722             2.198453    -26.164193  \n",
       "std        0.285787             0.911686     16.501854  \n",
       "min        0.000000             1.000000    -60.000000  \n",
       "25%        0.000000             2.000000    -39.000000  \n",
       "50%        0.000000             2.000000    -24.000000  \n",
       "75%        0.000000             3.000000    -12.000000  \n",
       "max        1.000000            20.000000      0.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_data_full_data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a70b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that will return the value count and frequency of each observation within a feature\n",
    "def value_cnt_norm_cal(df,feature):\n",
    "    ftr_value_cnt = df[feature].value_counts()\n",
    "    ftr_value_cnt_norm = df[feature].value_counts(normalize=True) * 100\n",
    "    ftr_value_cnt_concat = pd.concat([ftr_value_cnt, ftr_value_cnt_norm], axis=1)\n",
    "    ftr_value_cnt_concat.columns = ['Count', 'Frequency (%)']\n",
    "    return ftr_value_cnt_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34261384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create display general information about the feature\n",
    "def gen_info_feat(df,feature):\n",
    "    if feature == 'Age':\n",
    "        # change the feature to be express in positive numbers days\n",
    "        print('Description:\\n{}'.format((np.abs(df[feature])/365.25).describe()))\n",
    "        print('*'*50)\n",
    "        print('Object type:{}'.format(df[feature].dtype))\n",
    "    elif feature == 'Employment length':\n",
    "        # select only the rows where the rows are negative to ignore whose who have retired or unemployed\n",
    "        employment_len_no_ret = cc_train_copy['Employment length'][cc_train_copy['Employment length'] < 0]\n",
    "        employment_len_no_ret_yrs = np.abs(employment_len_no_ret)/365.25\n",
    "        print('Description:\\n{}'.format((employment_len_no_ret_yrs).describe()))\n",
    "        print('*'*50)\n",
    "        print('Object type:{}'.format(employment_len_no_ret.dtype))\n",
    "    elif feature ==  'Account age':\n",
    "        # change the account age to a positive number of months\n",
    "        print('Description:\\n{}'.format((np.abs(df[feature])).describe()))\n",
    "        print('*'*50)\n",
    "        print('Object type:{}'.format(df[feature].dtype))\n",
    "    else:\n",
    "        print('Description:\\n{}'.format(df[feature].describe()))\n",
    "        print('*'*50)\n",
    "        print('Object type:\\n{}'.format(df[feature].dtype))\n",
    "        print('*'*50)\n",
    "        value_cnt = value_cnt_norm_cal(df,feature)\n",
    "        print('Value count:\\n{}'.format(value_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27a10dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create a pie chart plot\n",
    "def create_pie_plot(df,feature):\n",
    "    if feature ==  'Dwelling' or 'Education level':\n",
    "        ratio_size = value_cnt_norm_cal(df, feature)\n",
    "        ratio_size_len = len(ratio_size.index)\n",
    "        ratio_list = []\n",
    "        for i in range(ratio_size_len):\n",
    "            ratio_list.append(ratio_size.iloc[i]['Frequency (%)'])\n",
    "        fig, ax = plt.subplots(figsize=(10,10))\n",
    "        # %1.2f%% display decimals in the pie chart with 2 decimal places\n",
    "        plt.pie(ratio_list, startangle=90, wedgeprops={'edgecolor' :'black'})\n",
    "        plt.title('Pie chart of {}'.format(feature))\n",
    "        plt.legend(loc='best',labels=ratio_size.index)\n",
    "        plt.axis('equal')\n",
    "        return plt.show()\n",
    "    else :\n",
    "        ratio_size = value_cnt_norm_cal(df, feature)\n",
    "        ratio_size_len = len(ratio_size.index)\n",
    "        ratio_list = []\n",
    "        for i in range(ratio_size_len):\n",
    "            ratio_list.append(ratio_size.iloc[i]['Frequency (%)'])\n",
    "        fig, ax = plt.subplots(figsize=(10,10))\n",
    "        # %1.2f%% display decimals in the pie chart with 2 decimal places\n",
    "        plt.pie(ratio_list, labels=ratio_size.index, autopct='%1.2f%%', startangle=90, wedgeprops={'edgecolor' :'black'})\n",
    "        plt.title('Pie chart of {}'.format(feature))\n",
    "        plt.legend(loc='best')\n",
    "        plt.axis('equal')\n",
    "        return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14cdb829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create a bar chart plot\n",
    "def create_bar_plot(df,feature):\n",
    "    if feature == 'Marital status' or 'Dwelling' or 'Job title' or 'Employment status' or 'Education level':\n",
    "        fig, ax = plt.subplots(figsize=(6,10))\n",
    "        sns.barplot(x=value_cnt_norm_cal(df,feature).index,y=value_cnt_norm_cal(df,feature).values[:,0])\n",
    "        ax.set_xticklabels(labels=value_cnt_norm_cal(df,feature).index,rotation=45,ha='right')\n",
    "        plt.xlabel('{}'.format(feature))\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('{} count'.format(feature))\n",
    "        return plt.show()\n",
    "    else :\n",
    "        fig, ax = plt.subplots(figsize=(6,10))\n",
    "        sns.barplot(x=value_cnt_norm_cal(df,feature).index,y=value_cnt_norm_cal(df,feature).values[:,0])\n",
    "        plt.xlabel('{}'.format(feature))\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('{} count'.format(feature))\n",
    "        return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66c85772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29165, 20)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_train_copy.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed007292",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutlierRemover(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,feat_with_outliers = ['Family member count','Income', 'Employment length']):\n",
    "        self.feat_with_outliers = feat_with_outliers\n",
    "    def fit(self,df):\n",
    "        return self\n",
    "    def transform(self,df):\n",
    "        if (set(self.feat_with_outliers).issubset(df.columns)):\n",
    "            # 25% quantile\n",
    "            Q1 = df[self.feat_with_outliers].quantile(.25)\n",
    "            # 75% quantile\n",
    "            Q3 = df[self.feat_with_outliers].quantile(.75)\n",
    "            IQR = Q3 - Q1\n",
    "            # keep the data within 1.5 IQR\n",
    "            df = df[~((df[self.feat_with_outliers] < (Q1 - 1.5 * IQR)) |(df[self.feat_with_outliers] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "            return df\n",
    "        else:\n",
    "            print(\"One or more features are not in the dataframe\")\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9390f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropFeatures(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,feature_to_drop = ['ID','Has a mobile phone','Children count']):\n",
    "        self.feature_to_drop = feature_to_drop\n",
    "    def fit(self,df):\n",
    "        return self\n",
    "    def transform(self,df):\n",
    "        if (set(self.feature_to_drop).issubset(df.columns)):\n",
    "            df.drop(self.feature_to_drop,axis=1,inplace=True)\n",
    "            return df\n",
    "        else:\n",
    "            print(\"One or more features are not in the dataframe\")\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "579db08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeConversionHandler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feat_with_days = ['Employment length', 'Age'], feat_with_months = ['Account age']):\n",
    "        self.feat_with_days = feat_with_days\n",
    "        self.feat_with_months = feat_with_months\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        if (set(self.feat_with_days).issubset(X.columns)) & (set(self.feat_with_months).issubset(X.columns)):\n",
    "            # convert days to absolute value\n",
    "            X[['Employment length','Age']] = np.abs(X[['Employment length','Age']])\n",
    "            # convert months to absolute value\n",
    "            X['Account age'] = np.abs(X['Account age'])\n",
    "            return X\n",
    "        else:\n",
    "            print(\"One or more features are not in the dataframe\")\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f6828c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetireeHandler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, df):\n",
    "        return self\n",
    "    def transform(self, df):\n",
    "        if 'Employment length' in df.columns:\n",
    "            # select rows with employment length is 365243 which corresponds to retirees\n",
    "            df_ret_idx = df['Employment length'][df['Employment length'] == 365243].index\n",
    "            # change 365243 to 0\n",
    "            df.loc[df_ret_idx,'Employment length'] = 0\n",
    "            return df\n",
    "        else:\n",
    "            print(\"Employment length is not in the dataframe\")\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02c46125",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkewnessHandler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,feat_with_skewness=['Income','Age']):\n",
    "        self.feat_with_skewness = feat_with_skewness\n",
    "    def fit(self,df):\n",
    "        return self\n",
    "    def transform(self,df):\n",
    "        if (set(self.feat_with_skewness).issubset(df.columns)):\n",
    "            # Handle skewness with cubic root transformation\n",
    "            df[self.feat_with_skewness] = np.cbrt(df[self.feat_with_skewness])\n",
    "            return df\n",
    "        else:\n",
    "            print(\"One or more features are not in the dataframe\")\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8d70ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinningNumToYN(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,feat_with_num_enc=['Has a work phone','Has a phone','Has an email']):\n",
    "        self.feat_with_num_enc = feat_with_num_enc\n",
    "    def fit(self,df):\n",
    "        return self\n",
    "    def transform(self,df):\n",
    "        if (set(self.feat_with_num_enc).issubset(df.columns)):\n",
    "            # Change 0 to N and 1 to Y for all the features in feat_with_num_enc\n",
    "            for ft in self.feat_with_num_enc:\n",
    "                df[ft] = df[ft].map({1:'Y',0:'N'})\n",
    "            return df\n",
    "        else:\n",
    "            print(\"One or more features are not in the dataframe\")\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9e6b352",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotWithFeatNames(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,one_hot_enc_ft = ['Gender', 'Marital status', 'Dwelling', 'Employment status', 'Has a car', 'Has a property', 'Has a work phone', 'Has a phone', 'Has an email']):\n",
    "        self.one_hot_enc_ft = one_hot_enc_ft\n",
    "    def fit(self,df):\n",
    "        return self\n",
    "    def transform(self,df):\n",
    "        if (set(self.one_hot_enc_ft).issubset(df.columns)):\n",
    "            # function to one hot encode the features in one_hot_enc_ft\n",
    "            def one_hot_enc(df,one_hot_enc_ft):\n",
    "                one_hot_enc = OneHotEncoder()\n",
    "                one_hot_enc.fit(df[one_hot_enc_ft])\n",
    "                # get the result of the one hot encoding columns names\n",
    "                feat_names_one_hot_enc = one_hot_enc.get_feature_names_out(one_hot_enc_ft)\n",
    "                # change the array of the one hot encoding to a dataframe with the column names\n",
    "                df = pd.DataFrame(one_hot_enc.transform(df[self.one_hot_enc_ft]).toarray(),columns=feat_names_one_hot_enc,index=df.index)\n",
    "                return df\n",
    "            # function to concatenat the one hot encoded features with the rest of features that were not encoded\n",
    "            def concat_with_rest(df,one_hot_enc_df,one_hot_enc_ft):\n",
    "                # get the rest of the features\n",
    "                rest_of_features = [ft for ft in df.columns if ft not in one_hot_enc_ft]\n",
    "                # concatenate the rest of the features with the one hot encoded features\n",
    "                df_concat = pd.concat([one_hot_enc_df, df[rest_of_features]],axis=1)\n",
    "                return df_concat\n",
    "            # one hot encoded dataframe\n",
    "            one_hot_enc_df = one_hot_enc(df,self.one_hot_enc_ft)\n",
    "            # returns the concatenated dataframe\n",
    "            full_df_one_hot_enc = concat_with_rest(df,one_hot_enc_df,self.one_hot_enc_ft)\n",
    "            return full_df_one_hot_enc\n",
    "        else:\n",
    "            print(\"One or more features are not in the dataframe\")\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cec9ed59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrdinalFeatNames(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,ordinal_enc_ft = ['Education level']):\n",
    "        self.ordinal_enc_ft = ordinal_enc_ft\n",
    "    def fit(self,df):\n",
    "        return self\n",
    "    def transform(self,df):\n",
    "        if 'Education level' in df.columns:\n",
    "            ordinal_enc = OrdinalEncoder()\n",
    "            df[self.ordinal_enc_ft] = ordinal_enc.fit_transform(df[self.ordinal_enc_ft])\n",
    "            return df\n",
    "        else:\n",
    "            print(\"Education level is not in the dataframe\")\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a261cd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxWithFeatNames(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,min_max_scaler_ft = ['Age', 'Income', 'Account age', 'Employment length']):\n",
    "        self.min_max_scaler_ft = min_max_scaler_ft\n",
    "    def fit(self,df):\n",
    "        return self\n",
    "    def transform(self,df):\n",
    "        if (set(self.min_max_scaler_ft).issubset(df.columns)):\n",
    "            min_max_enc = MinMaxScaler()\n",
    "            df[self.min_max_scaler_ft] = min_max_enc.fit_transform(df[self.min_max_scaler_ft])\n",
    "            return df\n",
    "        else:\n",
    "            print(\"One or more features are not in the dataframe\")\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4931c876",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OversampleSMOTE(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self,df):\n",
    "        return self\n",
    "    def transform(self,df):\n",
    "        if 'Is high risk' in df.columns:\n",
    "            # SMOTE function to oversample the minority class to fix the imbalance data\n",
    "            smote = SMOTE()\n",
    "            X_bal, y_bal = smote.fit_resample(df.loc[:, df.columns != 'Is high risk'],df['Is high risk'].astype('int64'))\n",
    "            df_bal = pd.concat([pd.DataFrame(X_bal),pd.DataFrame(y_bal)],axis=1)\n",
    "            return df_bal\n",
    "        else:\n",
    "            print(\"Is high risk is not in the dataframe\")\n",
    "            return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c0650dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA SAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42160340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_pipeline(df):\n",
    "    min_max_scaler_ft = ['Age', 'Income', 'Account age', 'Employment length']\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('outlier_remover', OutlierRemover()),\n",
    "        ('feature_dropper', DropFeatures()),\n",
    "        ('time_conversion_handler', TimeConversionHandler()),\n",
    "        ('retiree_handler', RetireeHandler()),\n",
    "        ('skewness_handler', SkewnessHandler()),\n",
    "        ('binning_num_to_yn', BinningNumToYN()),\n",
    "        ('one_hot_with_feat_names', OneHotWithFeatNames()),\n",
    "        ('ordinal_feat_names', OrdinalFeatNames()),\n",
    "        ('min_max_with_feat_names', MinMaxWithFeatNames()),\n",
    "        ('oversample_smote', OversampleSMOTE())\n",
    "    ])\n",
    "    df_pipe_prep = pipeline.fit_transform(df)\n",
    "    return df_pipe_prep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "562e86d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Job title'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8504/184355369.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcc_train_copy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcc_train_copy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Job title\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4911\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4912\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4913\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4914\u001b[0m         )\n\u001b[0;32m   4915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4148\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4149\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4150\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4152\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4184\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4185\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6015\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6017\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6019\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Job title'] not found in axis\""
     ]
    }
   ],
   "source": [
    "cc_train_copy = cc_train_copy.drop(columns = \"Job title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebcd557",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # Hide the copy warning\n",
    "cc_train_prep = full_pipeline(cc_train_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa08a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_train_prep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09416d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_train_prep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953fb743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the train data into X and y (target)\n",
    "X_cc_train_prep, y_cc_train_prep = cc_train_prep.loc[:, cc_train_prep.columns != 'Is high risk'], cc_train_prep['Is high risk'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877cc21b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadddb17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cdb566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a9d9d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5079800c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e20e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_data_full_data = pd.read_csv('application_record.csv')\n",
    "credit_status = pd.read_csv('credit_record.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5596ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'sgd':SGDClassifier(random_state=42),\n",
    "    'logistic_regression':LogisticRegression(random_state=42,max_iter=1000),\n",
    "#   'support_vector_machine':SVC(random_state=42,probability=True),\n",
    "    'gaussian_naive_bayes':GaussianNB(),\n",
    "    'k_nearest_neighbors':KNeighborsClassifier(),\n",
    "    'gradient_boosting':GradientBoostingClassifier(random_state=42),\n",
    "    'linear_discriminant_analysis':LinearDiscriminantAnalysis(),\n",
    "    'bagging':BaggingClassifier(random_state=42),\n",
    "    'neural_network':MLPClassifier(random_state=42,max_iter=1000),\n",
    "    'adaboost':AdaBoostClassifier(random_state=42),\n",
    "    'extra_trees':ExtraTreesClassifier(random_state=42),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23270df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_importance_plot(model, model_name):\n",
    "    if model_name not in ['support_vector_machine','gaussian_naive_bayes','k_nearest_neighbors','bagging','neural_network']:\n",
    "        # change xtick font size\n",
    "        plt.rcParams['xtick.labelsize'] = 12\n",
    "        plt.rcParams['ytick.labelsize'] = 12\n",
    "        # top 10 most predictive features\n",
    "        top_10_feat = FeatureImportances(model, relative=False, topn=10)\n",
    "        # top 10 least predictive features\n",
    "        bottom_10_feat = FeatureImportances(model, relative=False, topn=-10)\n",
    "        #change the figure size\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        #change x label font size\n",
    "        plt.xlabel('xlabel', fontsize=14)\n",
    "        # Fit to get the feature importances\n",
    "        top_10_feat.fit(X_cc_train_prep, y_cc_train_prep)\n",
    "        # show the plot\n",
    "        top_10_feat.show()\n",
    "        print('\\n')\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.xlabel('xlabel', fontsize=14)\n",
    "        # Fit to get the feature importances\n",
    "        bottom_10_feat.fit(X_cc_train_prep, y_cc_train_prep)\n",
    "        # show the plot\n",
    "        bottom_10_feat.show()\n",
    "        print('\\n')\n",
    "    else:\n",
    "        print('No feature importance for {0}'.format(model_name))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a2c5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_prediction_func(model_trn):\n",
    "    # check if y_train_copy_pred exists, if not create it\n",
    "    y_cc_train_pred_path = Path('saved_models/{0}/y_train_copy_pred_{0}.sav'.format(model_name))\n",
    "    try:\n",
    "        y_cc_train_pred_path.resolve(strict=True)\n",
    "    except FileNotFoundError:\n",
    "        #cross validation prediction with kfold = 10\n",
    "        y_cc_train_pred = cross_val_predict(model_trn,X_cc_train_prep,y_cc_train_prep,cv=10,n_jobs=-1)\n",
    "        #save the predictions\n",
    "        joblib.dump(y_cc_train_pred,y_cc_train_pred_path)\n",
    "        return y_cc_train_pred\n",
    "    else:\n",
    "        # if it exist load the predictions\n",
    "        y_cc_train_pred = joblib.load(y_cc_train_pred_path)\n",
    "        return y_cc_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30bd615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_func(model_name):\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    #plot confusion matrix\n",
    "    conf_matrix = ConfusionMatrixDisplay.from_predictions(y_cc_train_prep,y_prediction_func(model_trn),ax=ax, cmap='Blues',values_format='d')\n",
    "    # remove the grid\n",
    "    plt.grid(b=None)\n",
    "    # increase the font size of the x and y labels\n",
    "    plt.xlabel('Predicted label', fontsize=14)\n",
    "    plt.ylabel('True label', fontsize=14)\n",
    "    #give a title to the plot using the model name\n",
    "    plt.title('Confusion Matrix', fontsize=14)\n",
    "    #show the plot\n",
    "    plt.show()\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cec9ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve_func(model_trn,model_name):\n",
    "    # check if y probabilities file exists, if not create it\n",
    "    y_proba_path = Path('saved_models/{0}/y_cc_train_proba_{0}.sav'.format(model_name))\n",
    "    try:\n",
    "        y_proba_path.resolve(strict=True)\n",
    "    except FileNotFoundError:\n",
    "        y_cc_train_proba = model_trn.predict_proba(X_cc_train_prep)\n",
    "        joblib.dump(y_cc_train_proba,y_proba_path)\n",
    "    else:\n",
    "        # if path exist load the y probabilities file\n",
    "        y_cc_train_proba = joblib.load(y_proba_path)\n",
    "    skplt.metrics.plot_roc_curve(y_cc_train_prep, y_cc_train_proba, title = 'ROC curve for {0}'.format(model_name), cmap='cool',figsize=(8,6), text_fontsize='large')\n",
    "    #remove the gride\n",
    "    plt.grid(b=None)\n",
    "    plt.show()\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c02236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_func(model_trn, model_name):\n",
    "    # check if score file exists, if not create it\n",
    "    class_report_path = Path('saved_models/{0}/class_report_{0}.sav'.format(model_name))\n",
    "    try:\n",
    "        class_report_path.resolve(strict=True)\n",
    "    except FileNotFoundError:\n",
    "        # calculate the scores of the model\n",
    "        class_report = classification_report(y_cc_train_prep,y_prediction_func(model_trn))\n",
    "        print(class_report)\n",
    "        # save the scores\n",
    "        joblib.dump(class_report,class_report_path)\n",
    "    else:\n",
    "        # if it exist load the scores\n",
    "        class_report = joblib.load(class_report_path)\n",
    "        print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef5dd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,model_name):\n",
    "    # check if the model file exist and if not create, train and save it\n",
    "    model_file_path = Path('saved_models/{0}/{0}_model.sav'.format(model_name))\n",
    "    try:\n",
    "        model_file_path.resolve(strict=True)\n",
    "    except FileNotFoundError:\n",
    "        if model_name == 'sgd':\n",
    "            # for sgd, loss = 'hinge' does not have a predict_proba method. Therefore, we use a calibrated model\n",
    "            calibrated_model = CalibratedClassifierCV(model, cv=10, method='sigmoid')\n",
    "            model_trn = calibrated_model.fit(X_cc_train_prep,y_cc_train_prep)\n",
    "        else:\n",
    "            model_trn = model.fit(X_cc_train_prep,y_cc_train_prep)\n",
    "        joblib.dump(model_trn,model_file_path)\n",
    "        # plot the most and least predictive features\n",
    "        return model_trn\n",
    "    else:\n",
    "        # if path exist load the model\n",
    "        model_trn = joblib.load(model_file_path)\n",
    "        # plot the most and least predictive features\n",
    "        return model_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3707f41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder_check():\n",
    "    # check if the folder for saving the model exists, if not create it\n",
    "    if not os.path.exists('saved_models/{}'.format(model_name)):\n",
    "        os.makedirs('saved_models/{}'.format(model_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb8bd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name,model in classifiers.items():\n",
    "    # title formatting\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('  {}  '.center(50,'-').format(model_name))\n",
    "    print('\\n')\n",
    "    # check if the folder for saving the model exists, if not create it\n",
    "    folder_check()\n",
    "    # train the model\n",
    "    model_trn = train_model(model,model_name)\n",
    "    # print the scores from the classification report\n",
    "    score_func(model_trn, model_name)\n",
    "    # plot the ROC curve\n",
    "    roc_curve_func(model_trn,model_name)\n",
    "    # plot the confusion matrix\n",
    "    confusion_matrix_func(model_name)\n",
    "    # print the most and least predictive features\n",
    "    feat_importance_plot(model,model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d5f4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05569bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cb32f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a43ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
